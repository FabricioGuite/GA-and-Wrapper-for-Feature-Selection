# -*- coding: utf-8 -*-
"""Copy of GA_TDE3
Automatically generated by Colab.
Original file is located at
https://colab.research.google.com/drive/1bBwnGCrCZdbcGuPjVwtBTD4J68ABCNjy
### Imports
"""
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
import random
from time import time
from sklearn.metrics import accuracy_score

"""### Definição de funções
#### Baseline
"""
# Função baseline para avaliar a acurácia usando todas as características
def baseline(X_train, y_train, X_test, y_test):
    model = DecisionTreeClassifier(random_state=33)
    model.fit(X_train, y_train)
    pred = model.predict(X_test)
    acc = accuracy_score(y_test, pred)
    return acc

"""#### Algoritmo genético (com seleção por roleta)"""
# gera uma populacao aleatoria selecionando num_genes*prob genes
def generate_initial_population(num_chromosomes, num_genes, prob):
    population = []
    num_features = int(num_genes * prob)
    i = 0

    while i < num_chromosomes:
        random_genes = []
        while len(random_genes) < max(1, num_features):
            num = random.choice(range(0, num_genes))
            if num not in random_genes:
                random_genes.append(num)
        candidate = [0 for _ in range(num_genes)]
        for random_gene in random_genes:
            candidate[random_gene] = 1
        if candidate not in population:
            population.append(candidate)
        i += 1

    return population

# calculo da fitness de toda a populacao
def fitness(population, data):
    train_len = int(len(data) / 2)
    X_train = data.iloc[:train_len, 1:]
    y_train = data.iloc[:train_len, 0].values
    X_val = data.iloc[train_len:, 1:]
    y_val = data.iloc[train_len:, 0].values

    model = DecisionTreeClassifier(random_state=33)

    # avaliando a qualidade (fitness) de cada cromossomo de uma população
    fitness_score = []
    for i in range(len(population)):
        features_selected = []
        for j in range(len(population[i])):
            chromosome = population[i]
            if chromosome[j] == 1:
                features_selected.append(j)
        model.fit(X_train.iloc[:, features_selected], y_train)
        pred = model.predict(X_val.iloc[:, features_selected])
        score = float(accuracy_score(y_val, pred))
        fitness_score.append(score)

    return fitness_score

# retorna dois novos chromosomos a partir do cruzamento dos chromosomos pais
def crossover(chromosome1, chromosome2):
    position = random.randrange(1, len(chromosome1))
    offspring1 = chromosome1[:position] + chromosome2[position + 1:]
    offspring2 = chromosome2[:position] + chromosome1[position + 1:]
    return offspring1, offspring2

# retorna a mutacao de um chromosomo
def mutation(chromosome, mutation_rate):
    i = 1
    while i < len(chromosome):
        if random.random() <= mutation_rate:
            chromosome[i] = random.randrange(0, 255)
        i += 1
    return chromosome

# retorna um chromosomo utilizando o metodo de selecao por roleta
def roulette_wheel_selection(population, data):
    fitness_list = fitness(population, data)
    sum_fitness = sum(fitness_list)
    percentage_list = []
    cumulative_percentage = 0.0

    for fitness_score in fitness_list:
        percentage = fitness_score / sum_fitness
        cumulative_percentage += percentage
        percentage_list.append(cumulative_percentage)

    num = random.random()
    for i in range(len(percentage_list)):
        if num <= percentage_list[i]:
            return population[i]

def genetic_algorithm(population, data, mutation_rate):
    selected1 = roulette_wheel_selection(population, data)
    selected2 = roulette_wheel_selection(population, data)
    offspring1, offspring2 = crossover(selected1, selected2)
    offspring1 = mutation(offspring1, mutation_rate)
    offspring2 = mutation(offspring2, mutation_rate)
    population.append(offspring1)
    population.append(offspring2)

    fitness_score = fitness(population, data)
    print(" Fitness offspring 1:", "%.3f" % fitness_score[len(fitness_score) - 2])
    print(" Fitness offspring 2:", "%.3f" % fitness_score[len(fitness_score) - 1])

    for _ in range(2):
        index = fitness_score.index(min(fitness_score))
        population.pop(index)
        fitness_score.pop(index)

    print(" ", end="")
    for fs in fitness_score:
        print("%.3f" % fs, end=", ")
    print()

    max_index = fitness_score.index(max(fitness_score))
    return population[max_index], fitness_score[max_index]

# Função para testar melhor chromosomo retornado pelo algoritmo
def test_ga(chromosome, train_data, test_data):
    train_len = int(len(train_data) / 2)
    test_len = int(len(test_data) / 2)
    X_train = train_data.iloc[:train_len, 1:]
    y_train = train_data.iloc[:train_len, 0].values
    X_test = test_data.iloc[test_len:, 1:]
    y_test = test_data.iloc[test_len:, 0].values

    features_selected = []
    for i in range(len(chromosome)):
        if chromosome[i] == 1:
            features_selected.append(i)

    model = DecisionTreeClassifier(random_state=33)
    model.fit(X_train.iloc[:, features_selected], y_train)
    pred = model.predict(X_test.iloc[:, features_selected])
    score = float(accuracy_score(y_test, pred))

    return score, features_selected

"""#### Método Wrapper (Forward Selection)"""
def wrapper(data, X_test, y_test):
    # Separando os dados em treino e validação
    train_len = int(len(data) / 2)
    X_train = data.iloc[:train_len, 1:]
    y_train = data.iloc[:train_len, 0].values
    X_val = data.iloc[train_len:, 1:]
    y_val = data.iloc[train_len:, 0].values

    selected_features = []  # Conjunto inicial vazio de características
    remaining_features = list(range(X_train.shape[1]))  # Índices de todas as características
    best_score = 0  # Melhor pontuação inicializada como 0
    improving = True  # Variável para controlar se o desempenho está melhorando

    # Medindo o tempo
    train_start_time = time()

    # Loop para adicionar características até que não haja mais melhoria significativa
    while improving and remaining_features:
        best_feature = None
        best_feature_score = 0

        # Testa cada característica restante para ver qual melhora mais o desempenho
        for feature in remaining_features:
            current_features = selected_features + [feature]

            # Treina o modelo com o conjunto atual de características
            model = DecisionTreeClassifier(random_state=33)
            model.fit(X_train.iloc[:, current_features], y_train)

            # Avalia a acurácia nas características atuais
            pred = model.predict(X_val.iloc[:, current_features])
            score = accuracy_score(y_val, pred)

            # Guarda a característica que resulta na maior pontuação
            if score > best_feature_score:
                best_feature_score = score
                best_feature = feature

        # Adiciona a melhor característica encontrada e atualiza a melhor pontuação
        if best_feature is not None and best_feature_score > best_score:
            selected_features.append(best_feature)
            remaining_features.remove(best_feature)
            best_score = best_feature_score
            print(f"Feature Adicionada {best_feature}, Novo melhor resultado: {best_score}")
        else:
            improving = False  # Para o loop se não houver melhoria

    # Tempo total
    train_end_time = time()
    print("Tempo de treinamento", train_end_time - train_start_time, "s")

    # Treinamento final e avaliação nos dados de teste
    f_start_time = time()
    final_model = DecisionTreeClassifier(random_state=33)
    final_model.fit(X_train.iloc[:, selected_features], y_train)
    test_predictions = final_model.predict(X_test.iloc[:, selected_features])
    test_score = accuracy_score(y_test, test_predictions)
    f_end_time = time()

    print("Tempo de seleção de features:", f_end_time - f_start_time, "s")
    return selected_features, best_score, test_score

"""### Carregando dados de treinamento e teste"""
train_data = pd.read_csv("mnist_train.csv", sep=",")
test_data = pd.read_csv("mnist_test.csv", sep=",")
X_train = train_data.iloc[:, 1:]
y_train = train_data.iloc[:, 0].values
X_test = test_data.iloc[:, 1:]
y_test = test_data.iloc[:, 0].values

"""
### Rodando os algoritmos"""
random.seed(33)

"""#### Baseline"""
# Executando o baseline
train_start_time = time()
baseline_accuracy = baseline(X_train, y_train, X_test, y_test)
train_end_time = time()
print("Baseline Accuracy usando todas as características:", baseline_accuracy)
print("Tempo de treinamento", train_end_time - train_start_time, "s")

"""#### Algoritmo genético"""
population_count = 20
number_of_features = 784
probability_of_selection = 0.1
mutation_rate = 0.15
epochs = 8

# Geração de população inicial e execução do algoritmo
features_start_time = time()
population = generate_initial_population(
    population_count, number_of_features, probability_of_selection
)

best_chromosome = None
best_fitness = 0.0

for i in range(epochs):
    print("Epoch", i + 1)
    chromosome, score = genetic_algorithm(population, train_data, mutation_rate)
    if best_chromosome is None or score > best_fitness:
        best_chromosome = chromosome
        best_fitness = score

features_end_time = time()

# Teste do melhor chromosomo
train_start_time = time()
ga_accuracy, features_selected = test_ga(best_chromosome, train_data, test_data)
print("GA Accuracy usando", int(number_of_features * probability_of_selection), "features selecionadas:", ga_accuracy)
print("Tempo de seleção de features:", features_end_time - features_start_time, "s")
print("Tempo de treinamento", train_end_time - train_start_time, "s")
print("Features selecionadas:", features_selected)

"""#### Método Wrapper"""
selected_features, best_score, test_score = wrapper(train_data, X_test, y_test)
print("Features selecionadas:", selected_features)
print("Melhor resultado na validação:", best_score)
print("Desempenho nos dados de teste:", test_score)
